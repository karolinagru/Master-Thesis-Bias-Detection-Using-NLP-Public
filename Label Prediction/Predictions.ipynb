{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y enum34\n",
    "!pip install --upgrade pip\n",
    "!pip install farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!set NotebookApp.iopub_data_rate_limit=2000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.data_handler.processor import TextClassificationProcessor\n",
    "from farm.modeling.optimization import initialize_optimizer\n",
    "from farm.infer import Inferencer\n",
    "from farm.modeling.adaptive_model import AdaptiveModel\n",
    "from farm.modeling.language_model import LanguageModel\n",
    "from farm.modeling.prediction_head import MultiLabelTextClassificationHead\n",
    "from farm.modeling.tokenization import Tokenizer\n",
    "from farm.train import Trainer\n",
    "from farm.utils import set_all_seeds, MLFlowLogger, initialize_device_settings\n",
    "from pprint import PrettyPrinter\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import farm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "save_dir = Path(\"./saved_models/distilbert/6epochs_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Inferencer.load(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_600k_test = model.inference_from_file(file=\"./DataSetCreation/df_prediction_cols_600k.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = pd.read_csv('labels_new_distilbert.csv')\n",
    "label_list = label_list['0'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Germany',\n",
       " 'Asia',\n",
       " 'North_Europe',\n",
       " 'Eastern_Europe',\n",
       " 'Western_Europe',\n",
       " 'South_Europe',\n",
       " 'North_America',\n",
       " 'South_America',\n",
       " 'Africa',\n",
       " 'Oceania',\n",
       " 'married',\n",
       " 'partnership',\n",
       " 'unmarried',\n",
       " 'divorced',\n",
       " 'below1500',\n",
       " 'to4000',\n",
       " 'over4000',\n",
       " '40.0',\n",
       " '30.0',\n",
       " '50.0',\n",
       " '60.0',\n",
       " '-999.0',\n",
       " '20.0',\n",
       " '70.0',\n",
       " 'employed',\n",
       " 'public_office',\n",
       " 'unemployed',\n",
       " 'student',\n",
       " 'self-employed',\n",
       " 'other_employment']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_index = { \"Germany\" : 0, \n",
    "                \"Asia\" : 1,\n",
    "                'North_Europe' : 2,\n",
    "                'Eastern_Europe' : 3,\n",
    "                'Western_Europe' : 4,\n",
    "                'South_Europe': 5,\n",
    "                'North_America': 6,\n",
    "                'South_America': 7,\n",
    "                'Africa': 8,\n",
    "                'Oceania': 9,\n",
    "                'married': 10,\n",
    "                'partnership': 11,\n",
    "                'unmarried': 12,\n",
    "                'divorced': 13,\n",
    "                'below1500': 14,\n",
    "                'to4000': 15,\n",
    "                'over4000': 16,\n",
    "                '40.0': 17,\n",
    "                '30.0': 18,\n",
    "                '50.0': 19,\n",
    "                '60.0': 20,\n",
    "                '-999.0': 21,\n",
    "                '20.0': 22,\n",
    "                '70.0': 23,\n",
    "                'employed': 24,\n",
    "                'public_office': 25,\n",
    "                'unemployed': 26,\n",
    "                'student': 27,\n",
    "                'self-employed' : 28,\n",
    "                'other_employment': 29\n",
    "               }\n",
    "groups_labels = {\n",
    "    \n",
    "    'nationality': (0,9),\n",
    "    'marital_status': (10, 13),\n",
    "    'income_group': (14, 16),\n",
    "    'age_decade': (17, 23),\n",
    "    'employment_group': (24, 29)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_600k_lp = pd.read_csv('./DataSetCreation/df_newtext_na_600k_all_cols.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexts = [p['context'] for l in result_600k_test for p in l['predictions']  ]\n",
    "predictions = [p['probability'] for l in result_600k_test for p in l['predictions']  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read original dataset including hand-given labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "test_df_600k_lp = pd.read_csv('./DataSetCreation/df_newtext_na_600k_all_cols.csv', sep='\\t')\n",
    "test_df_600k_lp['prob_income_group'] = np.nan\n",
    "test_df_600k_lp['prob_employment_group'] = np.nan\n",
    "test_df_600k_lp['prob_marital_status'] = np.nan\n",
    "test_df_600k_lp['prob_nationality'] = np.nan\n",
    "test_df_600k_lp['prob_age_decade'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_600k_lp['age_decade'] = test_df_600k_lp.age_decade.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_600k_lp['age_decade'] = test_df_600k_lp['age_decade'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_600k_lp.income_group.replace({'missing_income':'missing_income_group'}, inplace=True)\n",
    "test_df_600k_lp.employment_group.replace({'missing_employment':'missing_employment_group'}, inplace=True)\n",
    "test_df_600k_lp.age_decade.replace({'-999.0':'missing_age_decade'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_600k_lp.rename(columns={'maritial_status':'marital_status'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_labels = list(labels_index.keys())\n",
    "treshold_prob = 0.5\n",
    "\n",
    "\n",
    "for cix, c in enumerate(contexts):\n",
    "    for gix, g in enumerate(groups_labels):\n",
    "        max_from_group = groups_labels[g][0] + np.argmax(predictions[cix][groups_labels[g][0]:groups_labels[g][1]])\n",
    "        if (test_df_600k_lp.at[cix,g]=='missing_'+g):\n",
    "            test_df_600k_lp.at[cix,g]=_labels[max_from_group]\n",
    "            test_df_600k_lp.at[cix,'prob_'+g]=max(predictions[cix][groups_labels[g][0]:groups_labels[g][1]])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_600k_lp.to_csv('./DataSetCreation/test_overwritten_labels_600k.tsv',sep='\\t', header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
