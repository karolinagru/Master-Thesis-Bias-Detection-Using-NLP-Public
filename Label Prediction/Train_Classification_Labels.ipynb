{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y enum34\n",
    "!pip install --upgrade pip\n",
    "!pip install farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!set NotebookApp.iopub_data_rate_limit=2000000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:25:36 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "06/22/2021 18:25:55 - WARNING - tensorflow -   From /home/ec2-user/anaconda3/envs/tensorflow_p36/gpu_cuda10.0/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fmt: off\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from farm.data_handler.data_silo import DataSilo\n",
    "from farm.data_handler.processor import TextClassificationProcessor\n",
    "from farm.modeling.optimization import initialize_optimizer\n",
    "from farm.infer import Inferencer\n",
    "from farm.modeling.adaptive_model import AdaptiveModel\n",
    "from farm.modeling.language_model import LanguageModel\n",
    "from farm.modeling.prediction_head import MultiLabelTextClassificationHead\n",
    "from farm.modeling.tokenization import Tokenizer\n",
    "from farm.train import Trainer\n",
    "from farm.utils import set_all_seeds, MLFlowLogger, initialize_device_settings\n",
    "import os.path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import farm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " __          __  _                            _        \n",
      " \\ \\        / / | |                          | |       \n",
      "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
      "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
      "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
      "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
      "  ______      _____  __  __  \n",
      " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
      " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
      " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
      " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
      " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
      "                                     |    |==|==|    |  |\n",
      "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
      "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      " \n",
      "INFO: 'classification' does not exist. Creating a new experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:00 - INFO - farm.utils -   Using device: CUDA \n",
      "06/22/2021 18:26:00 - INFO - farm.utils -   Number of GPUs: 8\n",
      "06/22/2021 18:26:00 - INFO - farm.utils -   Distributed Training: False\n",
      "06/22/2021 18:26:00 - INFO - farm.utils -   Automatic Mixed Precision: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devices available: cuda\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "        format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "        datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "        level=logging.INFO)\n",
    "\n",
    "ml_logger = MLFlowLogger(tracking_uri=\"./FARM_logs/final_prediction/\")\n",
    "ml_logger.init_experiment(experiment_name='classification', run_name=\"run_text_classification\")\n",
    "\n",
    "set_all_seeds(seed=123)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Devices available: {}\".format(device))\n",
    "\n",
    "device, n_gpu = initialize_device_settings(use_cuda=torch.cuda.is_available())\n",
    "n_epochs = 6\n",
    "batch_size = 526\n",
    "\n",
    "evaluate_every = 4000\n",
    "lang_model = \"distilbert-base-german-cased\"\n",
    "do_lower_case = True\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(lang_model)\n",
    "model = AutoModel.from_pretrained(lang_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:06 - INFO - filelock -   Lock 140552330730352 acquired on /home/ec2-user/.cache/huggingface/transformers/8d669fffc251fa3f490617e99cbe9777175fb84575b9e474aa9b5c04dd37a68d.381bf7fa8fc6b6a863694b3044643c123febc918ddb39b34a48285796ecf04bf.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807c51ba245143c4a920fe57fb375a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/464 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:06 - INFO - filelock -   Lock 140552330730352 released on /home/ec2-user/.cache/huggingface/transformers/8d669fffc251fa3f490617e99cbe9777175fb84575b9e474aa9b5c04dd37a68d.381bf7fa8fc6b6a863694b3044643c123febc918ddb39b34a48285796ecf04bf.lock\n",
      "06/22/2021 18:26:06 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'DistilBertTokenizer'\n",
      "06/22/2021 18:26:07 - INFO - filelock -   Lock 140552330267448 acquired on /home/ec2-user/.cache/huggingface/transformers/5bb297aad6870764f744be4eeecd4679617a15931cc1e0b373bd23919defdeea.4d65bbd3b91f2762e9d2c779d48ab14052439d3fcc8c3d2fe78c7322a9ac8d64.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3658e52f4c45a09bd686dd842a5372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/240k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:07 - INFO - filelock -   Lock 140552330267448 released on /home/ec2-user/.cache/huggingface/transformers/5bb297aad6870764f744be4eeecd4679617a15931cc1e0b373bd23919defdeea.4d65bbd3b91f2762e9d2c779d48ab14052439d3fcc8c3d2fe78c7322a9ac8d64.lock\n",
      "06/22/2021 18:26:07 - INFO - filelock -   Lock 140561127680152 acquired on /home/ec2-user/.cache/huggingface/transformers/a63f1d64fc50ca021f544776df546258fb07cf1b516893a586ddabbbfc0cf924.427a4a69da815751f698c649e071f9d0c6c9f0e6630a2da72e22342b013c8d3d.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ed5c24a75248328d04f87739280be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/479k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:08 - INFO - filelock -   Lock 140561127680152 released on /home/ec2-user/.cache/huggingface/transformers/a63f1d64fc50ca021f544776df546258fb07cf1b516893a586ddabbbfc0cf924.427a4a69da815751f698c649e071f9d0c6c9f0e6630a2da72e22342b013c8d3d.lock\n",
      "06/22/2021 18:26:09 - INFO - filelock -   Lock 140561127340688 acquired on /home/ec2-user/.cache/huggingface/transformers/dac255dfe6b8fb9ca00b63c716bca62de0c5044d016751583ea34f2d39606023.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad804eefd10420f861ed099530190c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:09 - INFO - filelock -   Lock 140561127340688 released on /home/ec2-user/.cache/huggingface/transformers/dac255dfe6b8fb9ca00b63c716bca62de0c5044d016751583ea34f2d39606023.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f.lock\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.load(\n",
    "        pretrained_model_name_or_path=lang_model,\n",
    "        do_lower_case=do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "label_list = pd.read_csv('labels_new_distilbert.csv')\n",
    "label_list = label_list['0'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list\n",
    "print(label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:26:12 - WARNING - farm.data_handler.processor -   Currently no support in Processor for returning problematic ids\n"
     ]
    }
   ],
   "source": [
    "metric = \"acc\"\n",
    "\n",
    "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
    "                                            max_seq_len=200,\n",
    "                                            data_dir=Path(\"./DataSetCreation/\"),\n",
    "                                            label_list=label_list,\n",
    "                                            label_column_name=\"label\",\n",
    "                                            metric=metric,\n",
    "                                            quote_char='\"',\n",
    "                                            multilabel=True,\n",
    "                                            train_filename=\"train_newtext.tsv\",\n",
    "                                            dev_filename=\"val_newtext.tsv\",\n",
    "                                            test_filename=\"test_newtext.tsv\",\n",
    "                                            dev_split=0,\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create a DataSilo that loads several datasets (train/dev/test), provides DataLoaders for them and calculates a few descriptive statistics of our datasets\n",
    "data_silo = DataSilo(\n",
    "        processor=processor,\n",
    "        batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Create an AdaptiveModel\n",
    "# a) which consists of a pretrained language model as a basis\n",
    "language_model = LanguageModel.load(lang_model)\n",
    "# b) and a prediction head on top that is suited for our task => Text classification\n",
    "prediction_head = MultiLabelTextClassificationHead(class_weights=data_silo.calculate_class_weights(task_name='text_classification'),\n",
    "    num_labels=len(label_list))\n",
    "\n",
    "model = AdaptiveModel(\n",
    "        language_model=language_model,\n",
    "        prediction_heads=[prediction_head],\n",
    "        embeds_dropout_prob=0.1,\n",
    "        lm_output_types=[\"per_sequence\"],\n",
    "        device=device)\n",
    "\n",
    "# 5. Create an optimizer\n",
    "model, optimizer, lr_schedule = initialize_optimizer(\n",
    "        model=model,\n",
    "        learning_rate= 3e-5,\n",
    "        device=device,\n",
    "        n_batches=len(data_silo.loaders[\"train\"]),\n",
    "        n_epochs=n_epochs)\n",
    " # 6. Feed everything to the Trainer, which keeps care of growing our model into powerful plant and evaluates it from time to time\n",
    "trainer_6_epochs_newtext_imbalanced = Trainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        data_silo=data_silo,\n",
    "        epochs=n_epochs,\n",
    "        n_gpu=n_gpu,\n",
    "        lr_schedule=lr_schedule,\n",
    "        evaluate_every=evaluate_every,\n",
    "        device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/22/2021 18:28:29 - INFO - farm.train -   \n",
      " \n",
      "\n",
      "          &&& &&  & &&             _____                   _             \n",
      "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
      "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
      "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
      "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
      "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
      " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
      "     &&     \\|||                                                   |___/\n",
      "             |||\n",
      "             |||\n",
      "             |||\n",
      "       , -=-~  .-^- _\n",
      "              `\n",
      "\n",
      "Train epoch 0/5 (Cur. train loss: 0.2585): 100%|██████████| 1930/1930 [1:23:14<00:00,  2.59s/it]\n",
      "Train epoch 1/5 (Cur. train loss: 0.2101): 100%|██████████| 1930/1930 [1:22:59<00:00,  2.58s/it]\n",
      "Train epoch 2/5 (Cur. train loss: 0.1798):   7%|▋         | 140/1930 [06:01<1:17:18,  2.59s/it]\n",
      "Evaluating:   0%|          | 0/552 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 10/552 [00:10<09:06,  1.01s/it]\u001b[A\n",
      "Evaluating:   4%|▎         | 20/552 [00:20<08:54,  1.01s/it]\u001b[A\n",
      "Evaluating:   4%|▎         | 20/552 [00:30<08:54,  1.01s/it]\u001b[A\n",
      "Evaluating:   5%|▌         | 30/552 [00:30<08:47,  1.01s/it]\u001b[A\n",
      "Evaluating:   7%|▋         | 40/552 [00:40<08:37,  1.01s/it]\u001b[A\n",
      "Evaluating:   9%|▉         | 50/552 [00:50<08:26,  1.01s/it]\u001b[A\n",
      "Evaluating:  11%|█         | 60/552 [01:00<08:15,  1.01s/it]\u001b[A\n",
      "Evaluating:  13%|█▎        | 71/552 [01:11<08:03,  1.00s/it]\u001b[A\n",
      "Evaluating:  15%|█▍        | 82/552 [01:22<07:51,  1.00s/it]\u001b[A\n",
      "Evaluating:  17%|█▋        | 93/552 [01:33<07:42,  1.01s/it]\u001b[A\n",
      "Evaluating:  19%|█▉        | 104/552 [01:44<07:29,  1.00s/it]\u001b[A\n",
      "Evaluating:  21%|██        | 115/552 [01:55<07:18,  1.00s/it]\u001b[A\n",
      "Evaluating:  23%|██▎       | 125/552 [02:05<07:08,  1.00s/it]\u001b[A\n",
      "Evaluating:  24%|██▍       | 135/552 [02:15<06:58,  1.00s/it]\u001b[A\n",
      "Evaluating:  26%|██▋       | 146/552 [02:26<06:46,  1.00s/it]\u001b[A\n",
      "Evaluating:  28%|██▊       | 157/552 [02:37<06:35,  1.00s/it]\u001b[A\n",
      "Evaluating:  30%|███       | 167/552 [02:47<06:26,  1.00s/it]\u001b[A\n",
      "Evaluating:  32%|███▏      | 177/552 [02:57<06:16,  1.00s/it]\u001b[A\n",
      "Evaluating:  34%|███▍      | 187/552 [03:07<06:05,  1.00s/it]\u001b[A\n",
      "Evaluating:  36%|███▌      | 197/552 [03:17<05:56,  1.00s/it]\u001b[A\n",
      "Evaluating:  38%|███▊      | 207/552 [03:27<05:46,  1.00s/it]\u001b[A\n",
      "Evaluating:  39%|███▉      | 217/552 [03:37<05:36,  1.00s/it]\u001b[A\n",
      "Evaluating:  39%|███▉      | 217/552 [03:48<05:36,  1.00s/it]\u001b[A\n",
      "Evaluating:  41%|████▏     | 228/552 [03:48<05:24,  1.00s/it]\u001b[A\n",
      "Evaluating:  43%|████▎     | 239/552 [04:00<05:15,  1.01s/it]\u001b[A\n",
      "Evaluating:  45%|████▌     | 249/552 [04:10<05:04,  1.01s/it]\u001b[A\n",
      "Evaluating:  47%|████▋     | 259/552 [04:20<04:54,  1.01s/it]\u001b[A\n",
      "Evaluating:  47%|████▋     | 259/552 [04:30<04:54,  1.01s/it]\u001b[A\n",
      "Evaluating:  49%|████▉     | 270/552 [04:31<04:42,  1.00s/it]\u001b[A\n",
      "Evaluating:  51%|█████     | 281/552 [04:42<04:31,  1.00s/it]\u001b[A\n",
      "Evaluating:  53%|█████▎    | 291/552 [04:52<04:21,  1.00s/it]\u001b[A\n",
      "Evaluating:  55%|█████▍    | 301/552 [05:02<04:12,  1.00s/it]\u001b[A\n",
      "Evaluating:  57%|█████▋    | 312/552 [05:13<04:00,  1.00s/it]\u001b[A\n",
      "Evaluating:  59%|█████▊    | 323/552 [05:24<03:49,  1.00s/it]\u001b[A\n",
      "Evaluating:  60%|██████    | 333/552 [05:34<03:39,  1.00s/it]\u001b[A\n",
      "Evaluating:  62%|██████▏   | 344/552 [05:45<03:28,  1.00s/it]\u001b[A\n",
      "Evaluating:  64%|██████▍   | 355/552 [05:56<03:17,  1.00s/it]\u001b[A\n",
      "Evaluating:  66%|██████▋   | 366/552 [06:07<03:05,  1.00it/s]\u001b[A\n",
      "Evaluating:  68%|██████▊   | 377/552 [06:18<02:55,  1.00s/it]\u001b[A\n",
      "Evaluating:  68%|██████▊   | 377/552 [06:28<02:55,  1.00s/it]\u001b[A\n",
      "Evaluating:  70%|███████   | 388/552 [06:29<02:44,  1.00s/it]\u001b[A\n",
      "Evaluating:  70%|███████   | 388/552 [06:40<02:44,  1.00s/it]\u001b[A\n",
      "Evaluating:  72%|███████▏  | 399/552 [06:40<02:33,  1.00s/it]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 409/552 [06:50<02:23,  1.00s/it]\u001b[A\n",
      "Evaluating:  76%|███████▌  | 419/552 [07:00<02:13,  1.00s/it]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 429/552 [07:10<02:03,  1.01s/it]\u001b[A\n",
      "Evaluating:  80%|███████▉  | 440/552 [07:21<01:52,  1.00s/it]\u001b[A\n",
      "Evaluating:  82%|████████▏ | 451/552 [07:32<01:41,  1.00s/it]\u001b[A\n",
      "Evaluating:  84%|████████▎ | 462/552 [07:43<01:30,  1.00s/it]\u001b[A\n",
      "Evaluating:  86%|████████▌ | 473/552 [07:54<01:19,  1.00s/it]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 483/552 [08:04<01:09,  1.01s/it]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 494/552 [08:15<00:58,  1.00s/it]\u001b[A\n",
      "Evaluating:  91%|█████████▏| 505/552 [08:26<00:47,  1.00s/it]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 516/552 [08:37<00:36,  1.00s/it]\u001b[A\n",
      "Evaluating:  95%|█████████▌| 527/552 [08:48<00:25,  1.00s/it]\u001b[A\n",
      "Evaluating:  97%|█████████▋| 537/552 [08:58<00:15,  1.00s/it]\u001b[A\n",
      "Evaluating:  97%|█████████▋| 537/552 [09:08<00:15,  1.00s/it]\u001b[A\n",
      "Evaluating: 100%|██████████| 552/552 [09:13<00:00,  1.00s/it]\u001b[A\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/22/2021 21:30:04 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 4000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "06/22/2021 21:30:04 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "06/22/2021 21:30:04 - INFO - farm.eval -   loss: 0.203989291196184\n",
      "06/22/2021 21:30:04 - INFO - farm.eval -   task_name: text_classification\n",
      "06/22/2021 21:30:04 - INFO - farm.eval -   acc: 0.9093997773318399\n",
      "06/22/2021 21:30:04 - INFO - farm.eval -   report: \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Germany     0.9776    0.8435    0.9056    211246\n",
      "            Asia     0.8446    0.7591    0.7996     33041\n",
      "    North_Europe     0.5558    0.9087    0.6898       701\n",
      "  Eastern_Europe     0.7593    0.7734    0.7663     20785\n",
      "  Western_Europe     0.6810    0.7730    0.7241      6661\n",
      "    South_Europe     0.7078    0.8090    0.7550      8346\n",
      "   North_America     0.5392    0.8759    0.6675      1861\n",
      "   South_America     0.5912    0.8973    0.7128      2571\n",
      "          Africa     0.6839    0.7786    0.7282     10099\n",
      "         Oceania     0.2878    0.9235    0.4388       196\n",
      "         married     0.8591    0.5134    0.6427     74720\n",
      "     partnership     0.6183    0.2787    0.3842     42354\n",
      "       unmarried     0.9058    0.5567    0.6896    163648\n",
      "        divorced     0.5400    0.4162    0.4701     14785\n",
      "       below1500     0.7592    0.4989    0.6022     56894\n",
      "          to4000     0.8814    0.3434    0.4942    178928\n",
      "        over4000     0.7448    0.3591    0.4846     59685\n",
      "            40.0     0.8731    0.2810    0.4251     72170\n",
      "            30.0     0.9254    0.4367    0.5934    132314\n",
      "            50.0     0.6560    0.3439    0.4513     22436\n",
      "            60.0     0.5005    0.5973    0.5447     12641\n",
      "          -999.0     0.2175    0.7701    0.3392      1057\n",
      "            20.0     0.8066    0.6395    0.7134     52904\n",
      "            70.0     0.2213    0.7904    0.3457      1985\n",
      "        employed     0.9361    0.6730    0.7830    208055\n",
      "   public_office     0.5805    0.5484    0.5640     10329\n",
      "      unemployed     0.6386    0.6586    0.6484     13992\n",
      "         student     0.7678    0.6885    0.7260     34674\n",
      "   self-employed     0.5986    0.4045    0.4828     13744\n",
      "other_employment     0.6442    0.4501    0.5299     14713\n",
      "\n",
      "       micro avg     0.8470    0.5570    0.6721   1477535\n",
      "       macro avg     0.6768    0.6197    0.6034   1477535\n",
      "    weighted avg     0.8571    0.5570    0.6591   1477535\n",
      "     samples avg     0.8036    0.5570    0.6337   1477535\n",
      "\n",
      "Train epoch 2/5 (Cur. train loss: 0.1546): 100%|██████████| 1930/1930 [1:31:21<00:00,  2.84s/it] \n",
      "Train epoch 3/5 (Cur. train loss: 0.1269): 100%|██████████| 1930/1930 [1:21:59<00:00,  2.55s/it]\n",
      "Train epoch 4/5 (Cur. train loss: 0.1158):  15%|█▍        | 280/1930 [11:54<1:10:00,  2.55s/it]\n",
      "Evaluating:   0%|          | 0/552 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   2%|▏         | 10/552 [00:10<09:04,  1.00s/it]\u001b[A\n",
      "Evaluating:   4%|▎         | 20/552 [00:20<08:53,  1.00s/it]\u001b[A\n",
      "Evaluating:   6%|▌         | 31/552 [00:31<08:41,  1.00s/it]\u001b[A\n",
      "Evaluating:   8%|▊         | 42/552 [00:42<08:30,  1.00s/it]\u001b[A\n",
      "Evaluating:  10%|▉         | 53/552 [00:53<08:19,  1.00s/it]\u001b[A\n",
      "Evaluating:  12%|█▏        | 64/552 [01:04<08:07,  1.00it/s]\u001b[A\n",
      "Evaluating:  14%|█▎        | 75/552 [01:14<07:56,  1.00it/s]\u001b[A\n",
      "Evaluating:  14%|█▎        | 75/552 [01:25<07:56,  1.00it/s]\u001b[A\n",
      "Evaluating:  16%|█▌        | 86/552 [01:26<07:46,  1.00s/it]\u001b[A\n",
      "Evaluating:  17%|█▋        | 96/552 [01:36<07:36,  1.00s/it]\u001b[A\n",
      "Evaluating:  19%|█▉        | 106/552 [01:46<07:28,  1.01s/it]\u001b[A\n",
      "Evaluating:  21%|██        | 116/552 [01:56<07:18,  1.01s/it]\u001b[A\n",
      "Evaluating:  23%|██▎       | 126/552 [02:06<07:09,  1.01s/it]\u001b[A\n",
      "Evaluating:  23%|██▎       | 126/552 [02:17<07:09,  1.01s/it]\u001b[A\n",
      "Evaluating:  25%|██▍       | 137/552 [02:17<06:57,  1.01s/it]\u001b[A\n",
      "Evaluating:  27%|██▋       | 148/552 [02:28<06:45,  1.00s/it]\u001b[A\n",
      "Evaluating:  29%|██▉       | 159/552 [02:39<06:34,  1.00s/it]\u001b[A\n",
      "Evaluating:  31%|███       | 169/552 [02:49<06:24,  1.00s/it]\u001b[A\n",
      "Evaluating:  32%|███▏      | 179/552 [02:59<06:14,  1.00s/it]\u001b[A\n",
      "Evaluating:  34%|███▍      | 190/552 [03:10<06:02,  1.00s/it]\u001b[A\n",
      "Evaluating:  36%|███▌      | 200/552 [03:20<05:53,  1.00s/it]\u001b[A\n",
      "Evaluating:  38%|███▊      | 211/552 [03:31<05:41,  1.00s/it]\u001b[A\n",
      "Evaluating:  40%|████      | 222/552 [03:42<05:32,  1.01s/it]\u001b[A\n",
      "Evaluating:  42%|████▏     | 233/552 [03:53<05:20,  1.00s/it]\u001b[A\n",
      "Evaluating:  44%|████▍     | 244/552 [04:04<05:08,  1.00s/it]\u001b[A\n",
      "Evaluating:  46%|████▌     | 255/552 [04:15<04:57,  1.00s/it]\u001b[A\n",
      "Evaluating:  46%|████▌     | 255/552 [04:25<04:57,  1.00s/it]\u001b[A\n",
      "Evaluating:  48%|████▊     | 266/552 [04:26<04:46,  1.00s/it]\u001b[A\n",
      "Evaluating:  48%|████▊     | 266/552 [04:37<04:46,  1.00s/it]\u001b[A\n",
      "Evaluating:  50%|█████     | 277/552 [04:37<04:35,  1.00s/it]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 288/552 [04:48<04:24,  1.00s/it]\u001b[A\n",
      "Evaluating:  54%|█████▍    | 298/552 [04:58<04:14,  1.00s/it]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 308/552 [05:08<04:04,  1.00s/it]\u001b[A\n",
      "Evaluating:  58%|█████▊    | 318/552 [05:18<03:54,  1.00s/it]\u001b[A\n",
      "Evaluating:  60%|█████▉    | 329/552 [05:29<03:43,  1.00s/it]\u001b[A\n",
      "Evaluating:  62%|██████▏   | 340/552 [05:40<03:31,  1.00it/s]\u001b[A\n",
      "Evaluating:  64%|██████▎   | 351/552 [05:51<03:21,  1.00s/it]\u001b[A\n",
      "Evaluating:  66%|██████▌   | 362/552 [06:02<03:10,  1.00s/it]\u001b[A\n",
      "Evaluating:  68%|██████▊   | 373/552 [06:13<02:59,  1.00s/it]\u001b[A\n",
      "Evaluating:  69%|██████▉   | 383/552 [06:23<02:49,  1.00s/it]\u001b[A\n",
      "Evaluating:  71%|███████   | 393/552 [06:33<02:39,  1.00s/it]\u001b[A\n",
      "Evaluating:  73%|███████▎  | 403/552 [06:43<02:29,  1.00s/it]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 414/552 [06:54<02:18,  1.00s/it]\u001b[A\n",
      "Evaluating:  75%|███████▌  | 414/552 [07:05<02:18,  1.00s/it]\u001b[A\n",
      "Evaluating:  77%|███████▋  | 425/552 [07:05<02:07,  1.00s/it]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 436/552 [07:16<01:56,  1.00s/it]\u001b[A\n",
      "Evaluating:  79%|███████▉  | 436/552 [07:27<01:56,  1.00s/it]\u001b[A\n",
      "Evaluating:  81%|████████  | 447/552 [07:27<01:45,  1.00s/it]\u001b[A\n",
      "Evaluating:  83%|████████▎ | 458/552 [07:39<01:34,  1.00s/it]\u001b[A\n",
      "Evaluating:  85%|████████▍ | 468/552 [07:49<01:24,  1.00s/it]\u001b[A\n",
      "Evaluating:  87%|████████▋ | 478/552 [07:59<01:14,  1.00s/it]\u001b[A\n",
      "Evaluating:  88%|████████▊ | 488/552 [08:09<01:04,  1.00s/it]\u001b[A\n",
      "Evaluating:  90%|█████████ | 498/552 [08:19<00:54,  1.00s/it]\u001b[A\n",
      "Evaluating:  92%|█████████▏| 508/552 [08:29<00:44,  1.00s/it]\u001b[A\n",
      "Evaluating:  94%|█████████▍| 518/552 [08:39<00:34,  1.00s/it]\u001b[A\n",
      "Evaluating:  96%|█████████▌| 529/552 [08:50<00:23,  1.00s/it]\u001b[A\n",
      "Evaluating:  98%|█████████▊| 540/552 [09:01<00:12,  1.00s/it]\u001b[A\n",
      "Evaluating: 100%|██████████| 552/552 [09:12<00:00,  1.00s/it]\u001b[A\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/23/2021 00:29:17 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | DEV SET | AFTER 8000 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "06/23/2021 00:29:17 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "06/23/2021 00:29:17 - INFO - farm.eval -   loss: 0.14489629536532012\n",
      "06/23/2021 00:29:17 - INFO - farm.eval -   task_name: text_classification\n",
      "06/23/2021 00:29:17 - INFO - farm.eval -   acc: 0.9435970495904779\n",
      "06/23/2021 00:29:17 - INFO - farm.eval -   report: \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Germany     0.9855    0.9006    0.9411    211246\n",
      "            Asia     0.9140    0.8643    0.8884     33041\n",
      "    North_Europe     0.7892    0.9187    0.8490       701\n",
      "  Eastern_Europe     0.8633    0.8605    0.8619     20785\n",
      "  Western_Europe     0.7838    0.8635    0.8217      6661\n",
      "    South_Europe     0.8453    0.8702    0.8576      8346\n",
      "   North_America     0.6982    0.8925    0.7835      1861\n",
      "   South_America     0.8088    0.9067    0.8549      2571\n",
      "          Africa     0.8522    0.8567    0.8545     10099\n",
      "         Oceania     0.7788    0.8980    0.8341       196\n",
      "         married     0.8964    0.6758    0.7706     74720\n",
      "     partnership     0.7998    0.5427    0.6466     42354\n",
      "       unmarried     0.9454    0.7144    0.8138    163648\n",
      "        divorced     0.6698    0.7022    0.6856     14785\n",
      "       below1500     0.8911    0.7122    0.7916     56894\n",
      "          to4000     0.9299    0.6559    0.7692    178928\n",
      "        over4000     0.8091    0.6094    0.6952     59685\n",
      "            40.0     0.8593    0.6061    0.7108     72170\n",
      "            30.0     0.9474    0.6521    0.7725    132314\n",
      "            50.0     0.6980    0.6512    0.6738     22436\n",
      "            60.0     0.6326    0.7643    0.6922     12641\n",
      "          -999.0     0.6335    0.7701    0.6951      1057\n",
      "            20.0     0.9167    0.7613    0.8318     52904\n",
      "            70.0     0.4825    0.7849    0.5976      1985\n",
      "        employed     0.9579    0.8068    0.8759    208055\n",
      "   public_office     0.6642    0.6872    0.6755     10329\n",
      "      unemployed     0.8804    0.8175    0.8478     13992\n",
      "         student     0.8958    0.7994    0.8449     34674\n",
      "   self-employed     0.6982    0.6696    0.6836     13744\n",
      "other_employment     0.8184    0.7472    0.7812     14713\n",
      "\n",
      "       micro avg     0.9068    0.7373    0.8133   1477535\n",
      "       macro avg     0.8115    0.7654    0.7801   1477535\n",
      "    weighted avg     0.9099    0.7373    0.8113   1477535\n",
      "     samples avg     0.8656    0.7373    0.7811   1477535\n",
      "\n",
      "Train epoch 4/5 (Cur. train loss: 0.1032): 100%|██████████| 1930/1930 [1:31:19<00:00,  2.84s/it] \n",
      "Train epoch 5/5 (Cur. train loss: 0.0873): 100%|██████████| 1930/1930 [1:22:05<00:00,  2.55s/it]\n",
      "Evaluating: 100%|██████████| 276/276 [04:36<00:00,  1.00s/it]\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "06/23/2021 03:06:07 - INFO - farm.eval -   \n",
      "\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "***************************************************\n",
      "***** EVALUATION | TEST SET | AFTER 11580 BATCHES *****\n",
      "***************************************************\n",
      "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "06/23/2021 03:06:07 - INFO - farm.eval -   \n",
      " _________ text_classification _________\n",
      "06/23/2021 03:06:07 - INFO - farm.eval -   loss: 0.13621727776778805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/23/2021 03:06:07 - INFO - farm.eval -   task_name: text_classification\n",
      "06/23/2021 03:06:07 - INFO - farm.eval -   acc: 0.9507767415208161\n",
      "06/23/2021 03:06:07 - INFO - farm.eval -   report: \n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "         Germany     0.9852    0.9197    0.9513    105591\n",
      "            Asia     0.9369    0.8680    0.9011     16464\n",
      "    North_Europe     0.8292    0.9079    0.8668       369\n",
      "  Eastern_Europe     0.8984    0.8639    0.8808     10370\n",
      "  Western_Europe     0.8206    0.8566    0.8382      3327\n",
      "    South_Europe     0.8834    0.8644    0.8738      4225\n",
      "   North_America     0.7294    0.8763    0.7961       889\n",
      "   South_America     0.8298    0.9033    0.8650      1355\n",
      "          Africa     0.8951    0.8571    0.8757      5059\n",
      "         Oceania     0.8349    0.8667    0.8505       105\n",
      "         married     0.9086    0.7056    0.7943     37649\n",
      "     partnership     0.8194    0.6068    0.6972     20984\n",
      "       unmarried     0.9531    0.7470    0.8375     81827\n",
      "        divorced     0.7177    0.7317    0.7246      7294\n",
      "       below1500     0.9133    0.7533    0.8256     28530\n",
      "          to4000     0.9394    0.7083    0.8076     89415\n",
      "        over4000     0.8327    0.6548    0.7331     29809\n",
      "            40.0     0.8834    0.6418    0.7435     36143\n",
      "            30.0     0.9433    0.7155    0.8138     65942\n",
      "            50.0     0.7415    0.6852    0.7122     11498\n",
      "            60.0     0.6949    0.7671    0.7292      6345\n",
      "          -999.0     0.8008    0.7976    0.7992       499\n",
      "            20.0     0.9267    0.7954    0.8560     26266\n",
      "            70.0     0.6042    0.7681    0.6763      1061\n",
      "        employed     0.9619    0.8344    0.8936    104329\n",
      "   public_office     0.6642    0.7314    0.6962      5033\n",
      "      unemployed     0.8906    0.8358    0.8623      7026\n",
      "         student     0.9109    0.8252    0.8659     17215\n",
      "   self-employed     0.7428    0.7042    0.7230      6806\n",
      "other_employment     0.8199    0.7815    0.8002      7345\n",
      "\n",
      "       micro avg     0.9198    0.7720    0.8394    738770\n",
      "       macro avg     0.8437    0.7858    0.8097    738770\n",
      "    weighted avg     0.9212    0.7720    0.8379    738770\n",
      "     samples avg     0.8775    0.7720    0.8082    738770\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WrappedDataParallel(\n",
       "  (module): AdaptiveModel(\n",
       "    (language_model): DistilBert(\n",
       "      (model): DistilBertModel(\n",
       "        (embeddings): Embeddings(\n",
       "          (word_embeddings): Embedding(31102, 768, padding_idx=0)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (transformer): Transformer(\n",
       "          (layer): ModuleList(\n",
       "            (0): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (1): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (2): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (3): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (4): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (5): TransformerBlock(\n",
       "              (attention): MultiHeadSelfAttention(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              )\n",
       "              (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (ffn): FFN(\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              )\n",
       "              (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): SequenceSummary(\n",
       "        (summary): Identity()\n",
       "        (first_dropout): Identity()\n",
       "        (last_dropout): Identity()\n",
       "      )\n",
       "    )\n",
       "    (prediction_heads): ModuleList(\n",
       "      (0): MultiLabelTextClassificationHead(\n",
       "        (feed_forward): FeedForwardBlock(\n",
       "          (feed_forward): Sequential(\n",
       "            (0): Linear(in_features=768, out_features=30, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (loss_fct): BCEWithLogitsLoss()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_6_epochs_newtext_imbalanced.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Hooray! You have a model. Store it:\n",
    "save_dir = Path(\"./saved_models/distilbert/6epochs_final\")\n",
    "model.save(save_dir)\n",
    "processor.save(save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
